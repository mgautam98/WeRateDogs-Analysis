{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "\n",
    "In this report I have summarised the process of data wrangling I have performed to gather the data from different sources to analyse and give interesting insights from the WeRateDogs twitter Handle.  \n",
    "[WeRateDogs](https://en.wikipedia.org/wiki/WeRateDogs) is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because [\"they're good dogs Brent.\"](http://knowyourmeme.com/memes/theyre-good-dogs-brent) WeRateDogs has over 4 million followers and has received international media coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the project include:  \n",
    "- Wrangle the data through multiple sources, includin Twitter API, data from Udacity Server and from CSV file and perform the following process\n",
    "    - Data Gathering\n",
    "    - Data Assessment\n",
    "    - Data Cleaning\n",
    "- Storing and Acting on Wrangled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, It was required to gather the data from three sources. \n",
    "- Gathering the data form tweeter archive of WeRateDogs of 2017 which contains almost 6000 tweets. It can be found in the twitter_archive_enhanced.csv file. \n",
    "- Fetching TSV file from udacity server with Image predictions of the dog breed form this [Link]\n",
    "- The retweet and favourite data related to the tweets collected using Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step I have assessed the data for the quality and the tideness. Quality assessment include:  \n",
    "- Completeness\n",
    "- Validity\n",
    "- Accuracy\n",
    "- Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have found the following issues related to the data:  \n",
    "**Twitter Archive :**  \n",
    "- Quality Issues  \n",
    "    - Empty values in in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, Some missing values in expanded URLs  \n",
    "    - Column with 835246439529840640 is having 0 as denominator  \n",
    "    - Change timestamp type to datetime  \n",
    "    - Unnecessary columns in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id,\n",
    "      retweeted_status_timestamp not needed for analysis, source  \n",
    "    - Unvalid names in name column like None, a, etc  \n",
    "\n",
    "\n",
    "- Tideness Issues  \n",
    "    - The doggo, floofer, pupper puppo are in different colums instead of single column  \n",
    "    - New column 'rating' which will be calculated as rating_numerator/rating_denominator  \n",
    "\n",
    "**Image Prediction :**  \n",
    "- Quality Issues  \n",
    "    - Images with no prediction of dogs, pl_dog, p2_dog, p3_dog are false, total 324 such rows exists  \n",
    "    - Underscores present in dog breed prediction names.  \n",
    "    - Invalid names like terrapin, suit which are not dog breed exists  \n",
    "    - dog breed names are not standardized, sometimes first letter is capitalized sometimes lower  \n",
    "\n",
    "\n",
    "- Tideness Issues  \n",
    "    - Make a single column with dog breed and place the max prediction dog beed there  \n",
    "    - Combine Image prediction and twitter archive dataframe  \n",
    "\n",
    "**Tweets data from API :**  \n",
    "- Quality Issues  \n",
    "     - Columns which are not necessary for analysis are present  \n",
    "\n",
    "- Tideness Issues  \n",
    "    - Combine tweet data and twitter archive dataframe  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "\n",
    "In this part I have cleaned the data and fixed the issues which I found in the assess part. Following operations were performed.    \n",
    "- Remove in tweets_archive the row with tweet_id 835246439529840640 as it is having 0 as denominator.  \n",
    "- Change the timestamp type to datetime in tweets_archive_copy  \n",
    "- Change None and a to in tweets_archive_copy.name to 'Unknown'  \n",
    "- Drop columns which are not necessary. Namely, in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id,   retweeted_status_user_id, retweeted_status_timestamp  \n",
    "- Remove underscore from the prediction names using str.replace function of pandas  \n",
    "- Make new column for breed and combine the results of p1, p2, p3 and store the values form pl_dog, p2_dog, p3_dog  \n",
    "- Remove unnecessary columns from the image_pred_copy using pandas drop function  \n",
    "- Capitalize the first letter of breed name and rest lower using pandas lower() and capitalize() functions  \n",
    "- Remove Ids which are not in archive from the tweet_data_copy  \n",
    "- Combine the doggo\tfloofer\tpupper\tpuppo into a single column. Here we can not use melt function as, it is not fixed that dog belongs to one of the typed it has None values too and after melting when we remove the values which are not needed then None can not be removed.  \n",
    "    - Drop the columns with doggo, floofer, pupper, puppo  \n",
    "- Merge the tweet archive and image_predictions using left join  \n",
    "- Merge the tweets_archive and tweet_data into single tabe using inner join operation  \n",
    "- Make new columnn rating which will be calculated as rating_numerator/rating_denominator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'wrangle_report.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
